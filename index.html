<!DOCTYPE html>
<html lang="pl">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Metody Optymalizacji Funkcji Wielu Zmiennych</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      line-height: 1.6;
      background-color: #f9f9f9;
      color: #333;
      padding: 20px;
    }
    h1, h2, h3 {
      color: #2c3e50;
    }
    .method {
      background: #fff;
      border-left: 6px solid #2980b9;
      padding: 15px;
      margin-bottom: 20px;
      box-shadow: 0 0 5px rgba(0,0,0,0.1);
    }
    ul {
      padding-left: 20px;
    }
    img {
      max-width: 100%;
      height: auto;
      display: block;
      margin: 20px auto;
      box-shadow: 0 0 5px rgba(0,0,0,0.2);
      border-radius: 5px;
    }
    pre {
            background: #272822;
            padding: 12px;
            border-radius: 8px;
            overflow-x: auto;
            color: #f8f8f2;
            font-size: 1em;
        }
        code {
            font-family: 'Courier New', monospace;
        }
  </style>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
  <h1>Metody Optymalizacji Funkcji Wielu Zmiennych</h1>

  <div class="method">
  <h2>Wprowadzenie do optymalizacji</h2>
  <p><strong>Optymalizacja</strong> to dziedzina matematyki i informatyki zajmujÄ…ca siÄ™ znajdowaniem najlepszych rozwiÄ…zaÅ„ dla danego problemu w okreÅ›lonych warunkach. W kontekÅ›cie funkcji wielu zmiennych, optymalizacja polega na znalezieniu takich wartoÅ›ci zmiennych, ktÃ³re minimalizujÄ… (lub maksymalizujÄ…) wartoÅ›Ä‡ funkcji celu.</p>
  <p>Proces optymalizacji jest nieodzownym elementem nowoczesnych technologii. Odgrywa kluczowÄ… rolÄ™ w inÅ¼ynierii (np. minimalizacja zuÅ¼ycia materiaÅ‚Ã³w), ekonomii (maksymalizacja zyskÃ³w, minimalizacja kosztÃ³w), biologii (modelowanie ekosystemÃ³w), aÅ¼ po sztucznÄ… inteligencjÄ™ (np. uczenie maszynowe, dostrajanie parametrÃ³w modeli).</p>
  <p>Funkcje celu w optymalizacji mogÄ… mieÄ‡ rÃ³Å¼ny charakter: mogÄ… byÄ‡ wypukÅ‚e, niewypukÅ‚e, gÅ‚adkie, nieliniowe, a nawet dyskretne. W zaleÅ¼noÅ›ci od wÅ‚aÅ›ciwoÅ›ci tych funkcji, stosuje siÄ™ rÃ³Å¼ne metody optymalizacji, takie jak metody gradientowe, bezgradientowe, heurystyczne i inne. W tym materiale skupimy siÄ™ na wybranych metodach numerycznych wykorzystywanych przy funkcjach wielu zmiennych, ze szczegÃ³lnym uwzglÄ™dnieniem metody najwiÄ™kszego spadku.</p>
</div>

  <div class="method">
    <h2>1. Metoda NajwiÄ™kszego Spadku (Steepest Descent)</h2>
    <p><strong>Opis:</strong> Iteracyjna metoda, ktÃ³ra w kaÅ¼dym kroku porusza siÄ™ w kierunku przeciwnym do gradientu funkcji, aby jak najszybciej zmniejszyÄ‡ jej wartoÅ›Ä‡.</p>
    <p><strong>Zalety:</strong></p>
    <ul>
      <li>Åatwa do zrozumienia i zaimplementowania</li>
      <li>UÅ¼yteczna dla dobrze uwarunkowanych funkcji</li>
    </ul>
    <p><strong>Wady:</strong></p>
    <ul>
      <li>Powolna zbieÅ¼noÅ›Ä‡ w "wÄ…skich dolinach"</li>
      <li>Wymaga doboru dÅ‚ugoÅ›ci kroku (learning rate)</li>
    </ul>
    <p><strong>Zastosowanie:</strong> Gdy mamy pochodne i stosunkowo proste funkcje.</p>
    <h3>Dane wejÅ›ciowe:</h3>
  <ul>
    <li>Funkcja celu \( f(x) \)</li>
    <li>Gradient funkcji \( \nabla f(x) \)</li>
    <li>Punkt poczÄ…tkowy \( x_0 \)</li>
    <li>Krok \( \alpha > 0 \)</li>
    <li>Tolerancja \( \varepsilon > 0 \)</li>
  </ul>

  <h3>Kroki algorytmu:</h3>
  <ol>
    <li>Inicjalizacja: wybierz \( x_0 \), ustaw \( k = 0 \)</li>
    <li>Powtarzaj:
      <ul>
        <li>Oblicz gradient: \( g_k = \nabla f(x_k) \)</li>
        <li>JeÅ›li \( \|g_k\| < \varepsilon \), zakoÅ„cz</li>
        <li>Zaktualizuj punkt: \( x_{k+1} = x_k - \alpha_k \cdot g_k \)</li>
        <li>ZnajdÅº najlepszy krok \( \alpha_k \) metodÄ… line search, tzn. znajdÅº minimum funkcji:
          \( \phi(\alpha) = f(x_k - \alpha g_k) \)
      </li>
        <li>ZwiÄ™ksz \( k = k + 1 \)</li>
      </ul>
    </li>
    <li>ZwrÃ³Ä‡ \( x_k \) jako minimum</li>
  </ol>

  <h3>ğŸ“Œ Uwagi:</h3>
  <ul>
    <li>JeÅ›li \( \alpha \) jest zbyt duÅ¼e â€“ brak zbieÅ¼noÅ›ci</li>
    <li>Zbyt maÅ‚e \( \alpha \) â€“ wolna zbieÅ¼noÅ›Ä‡</li>
    <li>Popularne podejÅ›cie: dobÃ³r \( \alpha \) przez line search</li>
  </ul>
  <h2>PrzykÅ‚ad Kodu</h2>
  <pre><code>
    import matplotlib.pyplot as plt
    import numpy as np
    from sympy import *
    
    # =========================
    # 1. Symboliczne pochodne
    # =========================
    
    x_sym, y_sym = symbols('x y')
    
    # Funkcja celu f(x, y)
    f_expr = x_sym**2 + y_sym**2
    
    # Gradient symbolicznie
    grad_expr = Matrix([diff(f_expr, var) for var in (x_sym, y_sym)])
    
    # Zamiana na funkcje numeryczne
    f = lambdify((x_sym, y_sym), f_expr, 'numpy')
    grad_f = lambdify((x_sym, y_sym), grad_expr, 'numpy')
    
    # =========================
    # 2. Parametry algorytmu
    # =========================
    
    point = np.array([2.0, 2.0])   # punkt startowy (x, y)
    eta = 0.1                     # krok
    tolerance = 1e-6
    max_iter = 1000
    
    points = [point.copy()]
    
    print("=== Gradient Descent Log ===\n")
    
    # =========================
    # 3. Gradient descent loop
    # =========================
    
    for i in range(max_iter):
        grad = np.array(grad_f(*point)).astype(float).flatten()
        new_point = point - eta * grad
        step_size = np.linalg.norm(new_point - point)
    
        # Logowanie
        print(f"Iteracja {i + 1}:")
        print(f"  Punkt:        {point}")
        print(f"  f(x, y):      {f(*point):.6f}")
        print(f"  Gradient:     {grad}")
        print(f"  DÅ‚ugoÅ›Ä‡ kroku: {step_size:.6e}\n")
    
        points.append(new_point.copy())
    
        if step_size < tolerance:
            print(f"âœ… ZbieÅ¼noÅ›Ä‡ osiÄ…gniÄ™ta po {i+1} iteracjach.\n")
            break
    
        point = new_point
    
    # =========================
    # 4. Wynik koÅ„cowy
    # =========================
    
    print("=== Wynik koÅ„cowy ===")
    print(f"Minimum znalezione w punkcie â‰ˆ {point}")
    print(f"f(x, y) â‰ˆ {f(*point):.6f}")
    
    # =========================
    # 5. Wykres poziomic + Å›cieÅ¼ka
    # =========================
    
    X, Y = np.meshgrid(np.linspace(-4, 6, 400), np.linspace(-4, 4, 400))
    Z = f(X, Y)
    
    points = np.array(points)
    
    plt.figure(figsize=(8, 6))
    contour = plt.contour(X, Y, Z, levels=30, cmap='viridis')
    plt.plot(points[:, 0], points[:, 1], 'ro--', label='ÅšcieÅ¼ka gradientu')
    plt.scatter(points[-1, 0], points[-1, 1], color='red', zorder=5)
    plt.xlabel("x")
    plt.ylabel("y")
    plt.title("Gradient descent dla f(x, y)")
    plt.grid(True)
    plt.legend()
    plt.colorbar(contour, label="f(x, y)")
    plt.show()
    </code></pre>
    <h3>PrzykÅ‚adowy wynik</h3>
    <pre>
      <code>
      âœ… ZbieÅ¼noÅ›Ä‡ osiÄ…gniÄ™ta po 61 iteracjach.

      === Wynik koÅ„cowy ===
      Minimum znalezione w punkcie â‰ˆ [3.06499108e-06 3.06499108e-06]
      f(x, y) â‰ˆ 0.000000
      </code>
    </pre>
    
    <img src="shortest.png" alt="Wizualizacja metody najwiÄ™kszego spadku">
  </div>

  <div class="method">
    <h2>2. Metoda SprzÄ™Å¼onych GradientÃ³w (Conjugate Gradient)</h2>
    
    <p><strong>Opis:</strong> Zaawansowana wersja Steepest Descent. W przeciwieÅ„stwie do klasycznego podejÅ›cia, zamiast kierunku najwiÄ™kszego spadku uÅ¼ywa tzw. kierunkÃ³w sprzÄ™Å¼onych. DziÄ™ki temu unika oscylacji w dolinach funkcji i szybciej osiÄ…ga minimum, zwÅ‚aszcza w przypadku funkcji kwadratowych.</p>
    <p>KaÅ¼dy nowy kierunek obliczany jest jako kombinacja kierunku gradientu oraz poprzedniego kierunku. To pozwala zredukowaÄ‡ liczbÄ™ iteracji i poprawia efektywnoÅ›Ä‡, szczegÃ³lnie w przypadku duÅ¼ych i rzadkich ukÅ‚adÃ³w liniowych.</p>
    <p><strong>Zalety:</strong> DuÅ¼e systemy rÃ³wnaÅ„, optymalizacja funkcji kwadratowych.</p>
    <h2>ğŸ” Conjugate Gradient Method â€“ Algorytm</h2>

<pre><code># Dane:
# A â€“ macierz (n x n), symetryczna i dodatnio okreÅ›lona
# b â€“ wektor wynikowy
# x0 â€“ punkt poczÄ…tkowy
# Îµ â€“ tolerancja dokÅ‚adnoÅ›ci
# max_iter â€“ maksymalna liczba iteracji

1. Ustaw x = x0
2. Oblicz r = b - AÂ·x       # wektor reszt
3. Ustaw p = r              # kierunek poczÄ…tkowy
4. Dla k = 0, 1, 2, ..., aÅ¼ do max_iter:
    a. Oblicz Î± = (ráµ—Â·r) / (páµ—Â·AÂ·p)
    b. Zaktualizuj x = x + Î±Â·p
    c. Oblicz r_new = r - Î±Â·AÂ·p
    d. JeÅ›li ||r_new|| < Îµ, przerwij (zbieÅ¼noÅ›Ä‡)
    e. Oblicz Î² = (r_newáµ—Â·r_new) / (ráµ—Â·r)
    f. Zaktualizuj p = r_new + Î²Â·p
    g. Ustaw r = r_new
5. ZwrÃ³Ä‡ x jako przybliÅ¼one rozwiÄ…zanie ukÅ‚adu Ax = b
</code></pre>
<img src="second_method.png" alt="Wizualizacja metody sprzÄ™Å¼onych gradientÃ³w">
  </div>

  <div class="method">
    <h2>3. Metoda Przeszukiwania Wzorca (Pattern Search)</h2>
    <img src="300px-Direct_search_BROYDEN.gif" alt="Wizualizacja dziaÅ‚ania przeszukiwania wzorca">
    <p><strong>Opis:</strong> Metoda nie wymagajÄ…ca znajomoÅ›ci pochodnych funkcji celu. DziaÅ‚a przez przeszukiwanie przestrzeni rozwiÄ…zaÅ„ wedÅ‚ug okreÅ›lonego schematu (wzorca), sprawdzajÄ…c, czy w jego sÄ…siedztwie wartoÅ›Ä‡ funkcji celu siÄ™ poprawia. W przeciwnym razie zmniejsza krok i prÃ³buje ponownie.</p>
    <p>Jest szczegÃ³lnie przydatna w sytuacjach, gdzie funkcja jest szumowa, nieliniowa, nigdzie niegÅ‚adka lub nieciÄ…gÅ‚a. DziÄ™ki temu znajduje zastosowanie w inÅ¼ynierii oraz optymalizacji eksperymentalnej.</p>
    <p><strong>Zalety:</strong> Problemy, gdzie pochodne sÄ… niedostÄ™pne lub funkcja jest nieregularna.</p>
  </div>

  <div class="method">
    <h2>4. Funkcja Rosenbrocka</h2>
    <img src="Rosenbruck.png" alt="Wizualizacja funkcji Rosenbrocka">
   
    <p><strong>Opis:</strong> Znana rÃ³wnieÅ¼ jako "banana function" ze wzglÄ™du na ksztaÅ‚t doliny, funkcja Rosenbrocka to klasyczny benchmark w testowaniu algorytmÃ³w optymalizacyjnych. Zawiera trudne do pokonania krzywizny i dÅ‚ugÄ…, wÄ…skÄ… dolinÄ™ prowadzÄ…cÄ… do globalnego minimum.</p>
    <p><strong>WzÃ³r:</strong> \( f(x, y) = (a - x)^2 + b(y - x^2)^2 \), zwykle \( a = 1, b = 100 \). Funkcja ta jest ciÄ…gÅ‚a i rÃ³Å¼niczkowalna, ale trudna do optymalizacji klasycznymi metodami.</p>
    <p><strong>Zastosowanie:</strong> Testowanie efektywnoÅ›ci metod optymalizacji.</p>
    <img src="rosembrock_sd.png" alt="Wizualizacja metody najwiÄ™kszego spadku">
  </div>
  <div class="method">
    <h2>Bibliografia</h2>
    <ul>
      <li>Boyd, S., & Vandenberghe, L. (2004). <em>Convex Optimization</em>. Cambridge University Press.</li>
      <li>Burden, R. L., & Faires, J. D. (2011). <em>Numerical Analysis</em> (9th ed.). Brooks/Cole.</li>
      <li>Wikipedia contributors. (n.d.). <em>Conjugate gradient method</em>. Retrieved from <a href="https://en.wikipedia.org/wiki/Conjugate_gradient_method" target="_blank">[LINK]</a></li>
      <li>MathWorks. (n.d.). <em>Pattern Search</em>. Retrieved from <a href="https://www.mathworks.com/help/gads/pattern-search.html" target="_blank">[LINK]</a></li>
      <li>Zbigniew Szadkowski -  Metody optymalizacji Metody gradientowe - Maj 2020</li>
      <li>Conjugate gradient methods - Alexandra Roberts, Anye Shi, Yue Sun <a href="https://www.mathworks.com/help/gads/pattern-search.html" target="_blank">[LINK]</a></li>  
    </ul>
  </div>
  <h3>WykonaÅ‚ : Jakub Litwin</h3>
</body>
</html>
